{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15fe996-296b-4022-9c0f-86abaab22ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from scipy.stats import rankdata\n",
    "import torch\n",
    "import dgl\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import gc\n",
    "import dgl.function as fn\n",
    "from dgl.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9acb5ce6-65b7-433f-99e6-b31c14cdcaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dir_path, indexes=None, add_self_loop=False):\n",
    "        super(GraphDataset, self).__init__()\n",
    "        self.dir_path = dir_path\n",
    "        self.graphs, label_dict = dgl.load_graphs(self.dir_path+'/dgl_graph.bin')\n",
    "        self.df = pd.read_csv(self.dir_path+'/overview_df.csv', index_col=0)\n",
    "        self.add_self_loop = add_self_loop\n",
    "        if indexes is None:\n",
    "            self.indexes = self.df.index\n",
    "        else:\n",
    "            self.indexes = indexes\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.indexes[i]\n",
    "        \n",
    "        row = self.df.loc[idx]\n",
    "        \n",
    "        graph_index = row.graph_index\n",
    "        graph = self.graphs[graph_index].clone()\n",
    "        if self.add_self_loop:\n",
    "            graph = dgl.add_self_loop(graph)\n",
    "        \n",
    "        seq_feature = np.load(self.dir_path+'/'+row.seq_feature_path)\n",
    "        seq = seq_feature['seq']\n",
    "        seq = torch.tensor(seq) \n",
    "        seq = torch.cat((seq[:, :1280], seq[:, -16:]), dim=1)\n",
    "        \n",
    "        surface_aa_feature = np.load(self.dir_path+'/'+row.surface_aa_feature_path)\n",
    "        surface_aa_seq = surface_aa_feature['surface_aa_seq']\n",
    "        surface_aa_seq = torch.tensor(surface_aa_seq) \n",
    "        surface_aa_seq = torch.cat((surface_aa_seq[:, :1280], surface_aa_seq[:, -16:]), dim=1)\n",
    "        \n",
    "        surface_pos = surface_aa_feature['surface_pos']\n",
    "        \n",
    "        graph.ndata['seq'] = seq\n",
    "        graph.ndata['surface_aa_seq'] = surface_aa_seq\n",
    "        graph.ndata['surface_pos'] = torch.from_numpy(surface_pos)\n",
    "        \n",
    "        label = row.get('pHmin', np.nan)\n",
    "        label_valid = True\n",
    "             \n",
    "        return graph, label, label_valid, idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e283d131-e475-4dc2-8658-3a72f541d5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, hidden_dim, layer_num=3):\n",
    "        super(GCN, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.activations = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "\n",
    "        for i in range(layer_num):\n",
    "            in_feats = hidden_dim if i == 0 else hidden_dim\n",
    "            out_feats = hidden_dim\n",
    "            self.convs.append(GraphConv(in_feats, out_feats))\n",
    "            self.activations.append(nn.LeakyReLU())\n",
    "            self.batch_norms.append(nn.BatchNorm1d(out_feats))\n",
    "\n",
    "        self.layer_num = layer_num\n",
    "        self.out_dim = hidden_dim * layer_num\n",
    "        \n",
    "    def forward(self, g, h):\n",
    "        hs = [h]\n",
    "        for conv, batch_norm, act in zip(self.convs, self.batch_norms, self.activations):\n",
    "            h = conv(g, h)\n",
    "            h = batch_norm(h)\n",
    "            h = act(h)\n",
    "            hs.append(h)\n",
    "        return torch.cat(hs, dim=-1)\n",
    "class GNNModel(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=256, dropout_rate=0.5):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.comp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_dim, hidden_dim),\n",
    "            torch.nn.LeakyReLU()\n",
    "        )\n",
    "        self.gcn = GCN(hidden_dim)\n",
    "        self.head = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(2048, self.gcn.out_dim),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(self.gcn.out_dim, 1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, g, wildtype_seq, surface_aa_seq, surface_pos):\n",
    "        wildtype_h = self.comp(wildtype_seq)\n",
    "        surface_aa_h = self.comp(surface_aa_seq)\n",
    "        wildtype_h = self.gcn(g, wildtype_h)\n",
    "        surface_aa_h = self.gcn(g, surface_aa_h)\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = wildtype_h\n",
    "            wildtype_hg = dgl.readout_nodes(g, 'h', op='sum') \n",
    "\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = surface_aa_h\n",
    "            surface_aa_hp = dgl.readout_nodes(g, 'h', op='sum')\n",
    "        h_all = torch.cat([wildtype_hg, surface_aa_hp], dim=-1)\n",
    "        #print(h_all.shape)\n",
    "        pred = self.head(h_all).squeeze()\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43b48977-bdc7-4b31-8441-640bb4ea1047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_259036/2536263083.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('ACENet.pth'))\n",
      "/tmp/ipykernel_259036/2536263083.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).                         | 0/1 [00:00<?, ?it/s]\n",
      "  label = torch.tensor(label).to(device).unsqueeze(1)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.2696, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.04s/it]\n"
     ]
    }
   ],
   "source": [
    "model = GNNModel(1296, 256).cuda()\n",
    "model.load_state_dict(torch.load('ACENet.pth'))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "test_dataset = GraphDataset(\"1fhe\")\n",
    "test_dataloader = dgl.dataloading.GraphDataLoader(test_dataset, batch_size=16, shuffle=False, drop_last=False, num_workers=26)\n",
    "test_labels = []\n",
    "test_predictions = []\n",
    "for graph, label, label_valid, original_index in tqdm(test_dataloader, leave=True):\n",
    "    graph = graph.to(device)\n",
    "    label = torch.tensor(label).to(device).unsqueeze(1)\n",
    "    label = label.squeeze()\n",
    "    seq, surface_aa_seq, surface_pos = graph.ndata['seq'], graph.ndata['surface_aa_seq'], graph.ndata['surface_pos']\n",
    "    with torch.no_grad():   \n",
    "        pred = model(graph, seq, surface_aa_seq, surface_pos)\n",
    "\n",
    "    # Collect predictions\n",
    "    # test_labels.extend(label.cpu().numpy())\n",
    "    # test_predictions.extend(pred.cpu().numpy())\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3d9434-96be-4363-bc80-248d8d82565e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (0) does not match length of index (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1fhe.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 替换为你的文件路径\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpHmin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_predictions\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 打印结果以验证\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[0;32m~/anaconda3/envs/dgl-test1/lib/python3.8/site-packages/pandas/core/frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3949\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3950\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dgl-test1/lib/python3.8/site-packages/pandas/core/frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4135\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4141\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4143\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4146\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4147\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4148\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4149\u001b[0m     ):\n\u001b[1;32m   4150\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/anaconda3/envs/dgl-test1/lib/python3.8/site-packages/pandas/core/frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4870\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/dgl-test1/lib/python3.8/site-packages/pandas/core/common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (0) does not match length of index (1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('1fhe.csv')  # 替换为你的文件路径\n",
    "df['pHmin'] = test_predictions\n",
    "\n",
    "# 打印结果以验证\n",
    "print(df)\n",
    "df.to_csv('1fhe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b9b676-b3c9-490a-bf57-035d9c58b077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgl-test",
   "language": "python",
   "name": "dgl-test1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
